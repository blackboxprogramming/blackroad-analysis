# ğŸ“Š GreenLight Analytics & Observability

**Layer 13: Production Visibility & User Behavior**

---

## ğŸ“Š Why Analytics & Observability Matters

**The Problem:** We build and deploy, but we're blind to what happens next.
- Is the API actually fast or slow?
- Are users hitting errors we don't know about?
- Which features do users actually use?
- Is the system healthy or degrading?

**The Solution:** Complete production visibility with real-time monitoring.
- Know about errors before users report them
- Track performance degradation immediately
- Understand user behavior and conversion
- Prevent incidents before they happen

---

## âš¡ Observability Events as GreenLight Steps

| Event | GreenLight Step | Step # | Emoji | State Transition | Severity |
|-------|-----------------|--------|-------|------------------|----------|
| Error detected | ğŸš¨ Detect | 16 | ğŸš¨âŒ | â†’ blocked | Critical |
| Performance alert | âš¡ Alert | 16 | âš¡âš ï¸ | â†’ blocked | High |
| Service degraded | ğŸ“‰ Degrade | 16 | ğŸ“‰âš ï¸ | â†’ blocked | High |
| Service recovered | âœ… Recover | 17 | âœ…ğŸ‰ | blocked â†’ wip | Info |
| Metric threshold | ğŸ“Š Alert | 16 | ğŸ“Šâš ï¸ | â†’ blocked | Medium |
| User action tracked | ğŸ‘¤ Track | 13 | ğŸ‘¤ğŸ“Š | â†’ wip | Info |
| Conversion event | ğŸ¯ Convert | 19 | ğŸ¯âœ… | wip â†’ done | Info |
| Log aggregated | ğŸ“ Aggregate | 13 | ğŸ“ğŸ“Š | â†’ wip | Info |

---

## ğŸ·ï¸ Monitoring Categories

| Category | Emoji | Tools | Purpose | Alert Threshold |
|----------|-------|-------|---------|-----------------|
| Error Tracking | ğŸš¨ | Sentry, Rollbar | Exceptions, crashes | Any error |
| APM | âš¡ | Datadog, New Relic | Performance, latency | P95 > 500ms |
| User Analytics | ğŸ‘¤ | Amplitude, Mixpanel | Behavior, funnels | Conversion < 10% |
| Logs | ğŸ“ | Better Stack, Axiom | Debug, audit trail | Error logs |
| Uptime | ğŸŒ | Pingdom, UptimeRobot | Availability | Downtime > 1min |
| Real User Monitoring | ğŸ“± | Sentry, DataDog RUM | Client-side perf | LCP > 2.5s |
| Synthetic Monitoring | ğŸ¤– | Checkly, Grafana | Proactive checks | Check fails |
| Infrastructure | ğŸ–¥ï¸ | Datadog, Grafana | CPU, memory, disk | CPU > 80% |

---

## ğŸ¨ Composite Patterns

### Error Tracking
```
ğŸš¨âŒğŸ‘‰ğŸ”¥ = Critical error detected, micro, urgent
ğŸ›ğŸ”ğŸ‘‰â­ = Error being investigated
âœ…ğŸ›ğŸ¢ğŸ‰ = Error resolved, macro
```

### Performance Monitoring
```
âš¡âš ï¸ğŸ‘‰ğŸ”¥ = Performance alert, slow queries
ğŸ“ŠğŸ“ˆğŸ¢ğŸ“Œ = Metrics trending up (good)
ğŸ“‰âš ï¸ğŸ‘‰ğŸ”¥ = Metrics degrading (bad)
```

### User Analytics
```
ğŸ‘¤ğŸ“ŠğŸ‘‰ğŸ“Œ = User action tracked
ğŸ¯âœ…ğŸ¢ğŸŒ = Conversion event (signup, purchase)
ğŸšªğŸ‘‹ğŸ‘‰âš ï¸ = User churn event
```

### Service Health
```
âœ…ğŸŒğŸ¢ğŸŒ = All systems operational
âš ï¸ğŸ“‰ğŸ‘‰ğŸ”¥ = Service degraded
ğŸš¨â›”ğŸ‘‰ğŸ”¥ = Service down, critical
âœ…ğŸ”„ğŸ¢ğŸ‰ = Service recovered
```

---

## ğŸ“ NATS Subject Patterns

### Error Events
```
greenlight.error.detected.critical.platform.{service}
greenlight.error.resolved.macro.platform.{error_id}
greenlight.error.recurring.critical.platform.{fingerprint}
```

### Performance Events
```
greenlight.performance.slow_query.critical.platform.{endpoint}
greenlight.performance.high_latency.critical.platform.{service}
greenlight.performance.memory_leak.critical.platform.{worker}
greenlight.performance.improved.macro.platform.{metric}
```

### User Analytics Events
```
greenlight.user.action.micro.platform.{event_name}
greenlight.user.conversion.macro.platform.{funnel}
greenlight.user.churn.macro.platform.{reason}
greenlight.user.retention.macro.platform.{cohort}
```

### Service Health Events
```
greenlight.service.up.macro.platform.{service}
greenlight.service.down.critical.platform.{service}
greenlight.service.degraded.critical.platform.{service}
greenlight.service.recovered.macro.platform.{service}
```

### Metrics Events
```
greenlight.metric.threshold.critical.platform.{metric_name}
greenlight.metric.anomaly.critical.platform.{metric_name}
greenlight.metric.trend.micro.platform.{metric_name}
```

---

## ğŸ”¨ Analytics & Observability Templates

### Error Tracking

```bash
# Error detected
gl_error_detected() {
    local service="$1"
    local error_type="$2"
    local message="$3"
    local stack_trace="${4:-no stack trace}"
    local severity="${5:-error}"

    local severity_emoji=""
    case "$severity" in
        critical|fatal) severity_emoji="ğŸš¨" ;;
        error) severity_emoji="âŒ" ;;
        warning) severity_emoji="âš ï¸" ;;
        *) severity_emoji="â„¹ï¸" ;;
    esac

    gl_log "${severity_emoji}âŒğŸ‘‰ğŸ”¥" \
        "error_detected" \
        "$service" \
        "Type: $error_type | Message: $message | Severity: $severity"
}

# Error resolved
gl_error_resolved() {
    local error_id="$1"
    local solution="$2"
    local affected_users="${3:-unknown}"

    gl_log "âœ…ğŸ›ğŸ¢ğŸ‰" \
        "error_resolved" \
        "$error_id" \
        "Solution: $solution | Affected users: $affected_users"
}

# Recurring error pattern
gl_error_recurring() {
    local fingerprint="$1"
    local occurrences="$2"
    local time_window="$3"

    gl_log "ğŸ”„ğŸš¨ğŸ‘‰ğŸ”¥" \
        "error_recurring" \
        "$fingerprint" \
        "Occurrences: $occurrences in $time_window - needs investigation"
}
```

### Performance Monitoring

```bash
# Performance alert
gl_performance_alert() {
    local metric_type="$1"  # latency, throughput, query_time, etc.
    local service="$2"
    local current_value="$3"
    local threshold="$4"
    local severity="${5:-warning}"

    local severity_emoji=""
    case "$severity" in
        critical) severity_emoji="ğŸš¨" ;;
        warning) severity_emoji="âš ï¸" ;;
        info) severity_emoji="â„¹ï¸" ;;
        *) severity_emoji="ğŸ“Š" ;;
    esac

    gl_log "${severity_emoji}âš¡ğŸ‘‰ğŸ”¥" \
        "performance_alert" \
        "$service" \
        "$metric_type: $current_value (threshold: $threshold)"
}

# Slow query detected
gl_slow_query_detected() {
    local query_type="$1"
    local duration="$2"
    local threshold="${3:-500ms}"
    local endpoint="${4:-unknown}"

    gl_log "ğŸŒğŸ“ŠğŸ‘‰ğŸ”¥" \
        "slow_query" \
        "$endpoint" \
        "Query: $query_type took $duration (threshold: $threshold)"
}

# Performance improved
gl_performance_improved() {
    local metric="$1"
    local before="$2"
    local after="$3"
    local improvement_pct="$4"

    gl_log "âœ…âš¡ğŸ¢ğŸ‰" \
        "performance_improved" \
        "$metric" \
        "Before: $before â†’ After: $after (${improvement_pct}% improvement)"
}
```

### User Analytics

```bash
# User action tracked
gl_user_action() {
    local event_name="$1"
    local user_id="${2:-anonymous}"
    local properties="${3:-}"

    gl_log "ğŸ‘¤ğŸ“ŠğŸ‘‰ğŸ“Œ" \
        "user_action" \
        "$event_name" \
        "User: $user_id | Properties: $properties"
}

# Conversion event
gl_conversion_event() {
    local funnel="$1"
    local user_id="$2"
    local value="${3:-}"
    local duration="${4:-unknown}"

    gl_log "ğŸ¯âœ…ğŸ¢ğŸŒ" \
        "conversion" \
        "$funnel" \
        "User: $user_id | Value: $value | Duration: $duration"
}

# User churn
gl_user_churn() {
    local user_id="$1"
    local reason="${2:-unknown}"
    local lifetime_value="${3:-unknown}"

    gl_log "ğŸšªğŸ‘‹ğŸ‘‰âš ï¸" \
        "user_churn" \
        "$user_id" \
        "Reason: $reason | LTV: $lifetime_value"
}

# Cohort retention
gl_cohort_retention() {
    local cohort="$1"
    local retention_rate="$2"
    local time_period="$3"

    gl_log "ğŸ“ŠğŸ‘¥ğŸ¢ğŸ“Œ" \
        "cohort_retention" \
        "$cohort" \
        "Retention: $retention_rate after $time_period"
}
```

### Service Health

```bash
# Service up
gl_service_up() {
    local service="$1"
    local uptime_pct="${2:-100}"
    local region="${3:-global}"

    gl_log "âœ…ğŸŒğŸ¢ğŸŒ" \
        "service_up" \
        "$service" \
        "Status: operational | Uptime: $uptime_pct% | Region: $region"
}

# Service down
gl_service_down() {
    local service="$1"
    local error="${2:-unknown}"
    local impact="${3:-all users}"

    gl_log "ğŸš¨â›”ğŸ‘‰ğŸ”¥" \
        "service_down" \
        "$service" \
        "Error: $error | Impact: $impact"
}

# Service degraded
gl_service_degraded() {
    local service="$1"
    local reason="$2"
    local performance_impact="${3:-unknown}"

    gl_log "âš ï¸ğŸ“‰ğŸ‘‰ğŸ”¥" \
        "service_degraded" \
        "$service" \
        "Reason: $reason | Impact: $performance_impact"
}

# Service recovered
gl_service_recovered() {
    local service="$1"
    local downtime_duration="$2"
    local recovery_action="${3:-automatic}"

    gl_log "âœ…ğŸ”„ğŸ¢ğŸ‰" \
        "service_recovered" \
        "$service" \
        "Downtime: $downtime_duration | Recovery: $recovery_action"
}
```

### Metrics & Thresholds

```bash
# Metric threshold exceeded
gl_metric_threshold() {
    local metric_name="$1"
    local current_value="$2"
    local threshold="$3"
    local severity="${4:-warning}"

    local severity_emoji=""
    case "$severity" in
        critical) severity_emoji="ğŸš¨" ;;
        warning) severity_emoji="âš ï¸" ;;
        info) severity_emoji="â„¹ï¸" ;;
        *) severity_emoji="ğŸ“Š" ;;
    esac

    gl_log "${severity_emoji}ğŸ“ŠğŸ‘‰ğŸ”¥" \
        "metric_threshold" \
        "$metric_name" \
        "Value: $current_value exceeds threshold: $threshold"
}

# Metric anomaly detected
gl_metric_anomaly() {
    local metric_name="$1"
    local expected_range="$2"
    local actual_value="$3"
    local confidence="${4:-high}"

    gl_log "ğŸ”ğŸ“ŠğŸ‘‰â­" \
        "metric_anomaly" \
        "$metric_name" \
        "Expected: $expected_range | Actual: $actual_value | Confidence: $confidence"
}

# Positive trend detected
gl_metric_trending_up() {
    local metric_name="$1"
    local trend_pct="$2"
    local time_period="$3"

    gl_log "ğŸ“ˆâœ…ğŸ¢ğŸ“Œ" \
        "metric_trending_up" \
        "$metric_name" \
        "Trend: +${trend_pct}% over $time_period"
}

# Negative trend detected
gl_metric_trending_down() {
    local metric_name="$1"
    local trend_pct="$2"
    local time_period="$3"

    gl_log "ğŸ“‰âš ï¸ğŸ‘‰ğŸ”¥" \
        "metric_trending_down" \
        "$metric_name" \
        "Trend: -${trend_pct}% over $time_period"
}
```

### Logs & Debugging

```bash
# Log aggregation complete
gl_logs_aggregated() {
    local service="$1"
    local log_count="$2"
    local time_period="$3"
    local errors_found="${4:-0}"

    gl_log "ğŸ“ğŸ“ŠğŸ‘‰ğŸ“Œ" \
        "logs_aggregated" \
        "$service" \
        "Logs: $log_count in $time_period | Errors: $errors_found"
}

# Critical log pattern
gl_log_pattern_critical() {
    local pattern="$1"
    local occurrences="$2"
    local services_affected="${3:-1}"

    gl_log "ğŸš¨ğŸ“ğŸ‘‰ğŸ”¥" \
        "critical_log_pattern" \
        "$pattern" \
        "Occurrences: $occurrences | Services affected: $services_affected"
}
```

### Real User Monitoring (RUM)

```bash
# Page load performance
gl_page_load_performance() {
    local page="$1"
    local lcp="$2"  # Largest Contentful Paint
    local fid="${3:-}"  # First Input Delay
    local cls="${4:-}"  # Cumulative Layout Shift

    local performance_rating=""
    if [[ ${lcp%ms} -lt 2500 ]]; then
        performance_rating="good"
        rating_emoji="âœ…"
    elif [[ ${lcp%ms} -lt 4000 ]]; then
        performance_rating="needs improvement"
        rating_emoji="âš ï¸"
    else
        performance_rating="poor"
        rating_emoji="âŒ"
    fi

    gl_log "${rating_emoji}ğŸ“±ğŸ‘‰ğŸ“Œ" \
        "page_load_performance" \
        "$page" \
        "LCP: $lcp (${performance_rating}) | FID: $fid | CLS: $cls"
}

# Browser error
gl_browser_error() {
    local error_message="$1"
    local browser="$2"
    local page="${3:-unknown}"
    local user_id="${4:-anonymous}"

    gl_log "ğŸš¨ğŸŒğŸ‘‰ğŸ”¥" \
        "browser_error" \
        "$page" \
        "Browser: $browser | Error: $error_message | User: $user_id"
}
```

### Synthetic Monitoring

```bash
# Health check passed
gl_health_check_passed() {
    local endpoint="$1"
    local response_time="$2"
    local region="${3:-global}"

    gl_log "âœ…ğŸ¤–ğŸ‘‰ğŸ“Œ" \
        "health_check_passed" \
        "$endpoint" \
        "Response time: $response_time | Region: $region"
}

# Health check failed
gl_health_check_failed() {
    local endpoint="$1"
    local error="$2"
    local region="${3:-global}"

    gl_log "âŒğŸ¤–ğŸ‘‰ğŸ”¥" \
        "health_check_failed" \
        "$endpoint" \
        "Error: $error | Region: $region"
}
```

---

## ğŸ¯ Example: Complete Observability Flow

### Scenario: Performance degradation detected, investigated, and resolved

```bash
# 1. Performance alert triggered
gl_performance_alert "api_latency" "blackroad-api" "1.2s" "500ms" "critical"
# [ğŸš¨âš¡ğŸ‘‰ğŸ”¥] performance_alert: blackroad-api â€” api_latency: 1.2s (threshold: 500ms)

# 2. Metric trending down
gl_metric_trending_down "api_throughput" "35" "last 15 minutes"
# [ğŸ“‰âš ï¸ğŸ‘‰ğŸ”¥] metric_trending_down: api_throughput â€” Trend: -35% over last 15 minutes

# 3. Slow queries detected
gl_slow_query_detected "user_lookup" "2.3s" "500ms" "/api/users"
# [ğŸŒğŸ“ŠğŸ‘‰ğŸ”¥] slow_query: /api/users â€” Query: user_lookup took 2.3s (threshold: 500ms)

# 4. Error spike detected
gl_error_recurring "timeout-db-connection" "47" "last 10 minutes"
# [ğŸ”„ğŸš¨ğŸ‘‰ğŸ”¥] error_recurring: timeout-db-connection â€” Occurrences: 47 in last 10 minutes - needs investigation

# 5. User impact tracked
gl_user_action "checkout_abandoned" "user_789" "error: timeout"
# [ğŸ‘¤ğŸ“ŠğŸ‘‰ğŸ“Œ] user_action: checkout_abandoned â€” User: user_789 | Properties: error: timeout

# 6. Service degraded
gl_service_degraded "blackroad-api" "Database connection pool exhausted" "50% slower responses"
# [âš ï¸ğŸ“‰ğŸ‘‰ğŸ”¥] service_degraded: blackroad-api â€” Reason: Database connection pool exhausted | Impact: 50% slower responses

# 7. Root cause identified (from Context layer)
gl_root_cause_identified "perf-001" "Database connection pool size too small for traffic spike" "high"
# [ğŸ¯ğŸ›ğŸ¢â­] root_cause_identified: perf-001 â€” Root cause: Database connection pool size too small for traffic spike | Confidence: high

# 8. Fix deployed
gl_deploy "blackroad-api" "https://api.blackroad.io" "Increased DB connection pool: 10 â†’ 50" "ğŸ¢" "ğŸ”§"
# [ğŸš€ğŸ¢ğŸ”§âœ…] deployed: blackroad-api â€” URL: https://api.blackroad.io. Increased DB connection pool: 10 â†’ 50

# 9. Performance improved
gl_performance_improved "api_latency" "1.2s" "180ms" "85"
# [âœ…âš¡ğŸ¢ğŸ‰] performance_improved: api_latency â€” Before: 1.2s â†’ After: 180ms (85% improvement)

# 10. Service recovered
gl_service_recovered "blackroad-api" "12 minutes" "manual deployment"
# [âœ…ğŸ”„ğŸ¢ğŸ‰] service_recovered: blackroad-api â€” Downtime: 12 minutes | Recovery: manual deployment

# 11. Users converting again
gl_conversion_event "checkout" "user_790" "$149" "45s"
# [ğŸ¯âœ…ğŸ¢ğŸŒ] conversion: checkout â€” User: user_790 | Value: $149 | Duration: 45s

# 12. Metrics back to normal
gl_metric_trending_up "api_throughput" "120" "last 15 minutes"
# [ğŸ“ˆâœ…ğŸ¢ğŸ“Œ] metric_trending_up: api_throughput â€” Trend: +120% over last 15 minutes

# 13. Learning documented (Context layer)
gl_learning_discovered "infrastructure-capacity" "Monitor connection pool usage, auto-scale before exhaustion" "Prevented 85% performance degradation"
# [ğŸ’¡âœ¨ğŸ‘‰â­] learning_discovered: infrastructure-capacity â€” Insight: Monitor connection pool usage, auto-scale before exhaustion | Evidence: Prevented 85% performance degradation
```

**Result:** Complete incident lifecycle tracked from detection â†’ investigation â†’ resolution â†’ recovery â†’ learning.

---

## ğŸ“Š Key Metrics to Track

### Performance Metrics
- **API Latency** (P50, P95, P99)
- **Database Query Time**
- **Worker Execution Time**
- **Page Load Time** (LCP, FID, CLS)
- **Error Rate**

### Business Metrics
- **Conversion Rate** (signup, checkout, etc.)
- **Revenue** (MRR, ARR)
- **Churn Rate**
- **User Retention** (Day 1, Day 7, Day 30)
- **Customer Lifetime Value**

### Infrastructure Metrics
- **CPU Usage**
- **Memory Usage**
- **Disk Usage**
- **Network Throughput**
- **Request Rate**

### User Behavior Metrics
- **Active Users** (DAU, MAU)
- **Session Duration**
- **Feature Adoption**
- **Funnel Drop-off**
- **User Journey Completion**

---

## ğŸ“š Integration Checklist

- [x] Mapped observability events to GreenLight workflow
- [x] Created monitoring categories (8 types)
- [x] Extended NATS subjects for analytics events
- [x] Built 25+ observability templates
- [x] Error tracking & resolution
- [x] Performance monitoring & alerts
- [x] User analytics & conversion tracking
- [x] Service health monitoring
- [x] Metric threshold alerts
- [x] Log aggregation
- [x] Real User Monitoring (RUM)
- [x] Synthetic monitoring
- [x] Infrastructure metrics
- [x] Incident lifecycle tracking

---

**Created:** December 23, 2025 ğŸŒ¸
**For:** Analytics & Observability
**Version:** 2.0.0-observability
**Status:** ğŸ”¨ IMPLEMENTATION
**Built by:** Cece (for production visibility)

